# How to Invent the Future II - Alan Kay

Speaker 1: I kept on rewriting the title. This is not a bad title for this class.  Another way of looking at it is, instead of trying to move forward from here,  where everything is confusing and the present looks like reality, we want to go out  to the future and bring it back. We talked about some process and methods. Today  we're going to talk about a few of the gazillion things. Of course I didn't  get done last week, which made this week even more, and finally I decided, "Screw  it, I'm going to do both of these talks again without an audience to do  them to their natural length," because the destiny for this is being online, and online  people are not confined to 50-minute hours. I'm sure Sam was all for that. Great.  Again, here's my email address. Out of all the people who are tuned into this  talk and in the classroom, I've got three emails, one of which is interesting. That  means that either or both of, my talk isn't interesting or you're not interesting or  both. Try and least disabuse me of the latter. Okay, so to start off with,  here's Leonardo. Pretty smart guy. Imagine if you were born with twice Leonardo's IQ. Think  about how easy it would be to get into Stanford. Maybe you do have twice  Leonardo's IQ, but suppose you were born with twice Leonardo's IQ in 10,000 BC. How  far are you going to get? Zip, right? Before they burn you at the stake  or whatever they did back then. Yeah, so, here's a guy with nowhere near Leonardo's  IQ, Henry Ford. Whereas Leonardo could not invent a single motor for any of his  vehicles, think about that, so here was smart but he wasn't that smart, Henry Ford  was able to put together processes that allowed him to make millions and millions of  cars, sell them for about $800 a piece, and the difference between the two was  that Ford was born into the right century and Leonardo was born into the wrong  century. The knowledge that had accumulated in the 19th century made much more difference than  any level of smartness. Where did that knowledge came from? It came, might as well  pick Newton if you're going to pick anybody, it came because the context was changed  from the Middle Ages and the Renaissance to something completely different in the 17th century,  and Newton made the biggest change of anybody. We could call that change a change  in outlook, we could call it a change in context, worldview, point of view, whatever  you want. I'm numbering rules for you, I decided to go back and start with  zero. The zeroth rule here, probably the most important one, is to make progress here,  let me move this guy off, context or point of view is worth 80 IQ  points. If you've got the context of science and math, you're gazillion times smarter effectively  than the smartest people of antiquity, like Archimedes. A person who learns calculus with an  IQ of 110 or 120 can do things that the great geniuses of the past  can't do. We can sum that up by saying knowledge is silver, context is gold,  and IQ is just lead. It's a lead weight on you. The biggest problem with  most people who are at your level and going to the next level is, you're  always the smartest people in your classroom or room at home, but that only means  you're the smartest people amongst 30 or 100. If you happen to be in a  room that had the 100 smartest people in the world and you were the smartest  person in that room, you're still not as smart as the 99 working together. Being  clever doesn't do it. This is the simplest , is the IQ . Tony Hoare,  really great guy, was here at Stanford for a while, Turing winner, said, "Debugging is  harder than programming, so don't use all your cleverness to write the program." Anybody recognize  this? Anybody write programs here? Let me see hands. Yeah. People are so clever writing  the program, they forget that debugging is harder. That's true about anything. That's principle number  one, we had zero. Here's a summary of what I showed you, and the number  two one at the top there is that the goodness of the results correlates most  strongly with the goodness of the funders. This is the simplest way of summing up  the past. Because you have to realize, the difference in the past wasn't that the  people were smarter back then. We weren't smarter than the smart people today. Every generation  has really smart people. The difference in whether you get enormous results or not is  in this context idea and the funders that support it. One of the ways of  thinking about them is, as opposed to getting gold medals like a bunch of us  have gotten in our 60s and 70s, 40 years after you did the deeds, good  funders give out the gold medals ahead of time knowing that 70% of them were  going to turn to lead. Because the funders give it out before you've gotten the  results. This will be a slide that you can use later on. It's basically what  I said last time. Last time we looked at four systems, a sketchpad, we didn't  really look at the Englebart System, but it's easy to find out about online. We  looked at the first really good gesture system, GRAIL, and we saw that Ivan Sutherland,  again, invented VR, long long before it ever came to use. I really rush past  personal computers, and the first thing was kind of like a personal computer, it was  kind of cute, was Harry Huskey's Bendix G15 in the mid-50s. This was really early.  Harry just left us at a few years over the age of 100, really wonderful  guy. Here's my vote for the first real personal computer called the LINC by Wes  Clark. Wes Clark also did the building-sized computer that Sketchpad was done on, so he  liked to work both large and small. Here's one I did with Ed Cheadle, looks  kind of modern, and an idea I had in 1968 which struck me really deeply,  not because it was a tablet but because it was a thing that children needed.  I'd learned from Seymour Papert, what children could actually do with computers and that seized  me in a romantic fashion. We looked at this idea of better and perfect are  the enemy of what is actually needed. In other words, we have to draw thresholds  in order to know where you are, else you're just measuring local variations. You don't  know whether they're good or bad. The last thing we did on Tuesday was looking  at this process of taking a glimmer of an idea out 30 or more years  to see if it makes more sense 30 years from now than it seems to  now, and if it does, you bring it back, simulate it by making supercomputers that  allow you to do the software, and five or eight years later, you've got something  that will revolutionize the world. This is where trillions rather than billions comes in, because  you create an industry. Last time, I didn't get a chance to show you just  one of the examples of what PARC did, so I thought I'd do it. Today,  and this is a self-portrait, because now I have extracted stuff from a demo, but  this is system we brought back to life from 1978. This is a self-portrait, so  this is the successor to the Alto, called the Dorado, so it had now a  bigger than XVGA screen, rather than the portrait model. This dithering technique was invented at  the same time in the 70s by Bob Floyd and Steinberg, and partly done at  PARC. This is what a typical image on only a few computers in the world  looked like back then, one bit per point. Where do we get this system from?  Well, here's the Xerox dump, and if you look closely there, there's a disk pack.  Actually got Xerox throughout most of the disk packs of the work that was done  at Xerox PARC. A few of them got rescued. Here it is, a few hundred  files on there. One of them happened to be most of a system that we  did in 1978, and it's of partial interest because the next year, it was the  stuff that Steve Jobs got shown during his famous visit too. You have a little  flavor here. Now what we did is, we brought this back to live, and it  was relatively easy because this system is called "Smalltalk-78", is a pure object system, and  so it resembles the internet. This is an internet self-portrait, and it's just as good  a self-portrait of Smalltalk because the idea was to have the one-to-one correspondence between the  idea of little logical computers, which is what we called objects, that could send messages  around and make an entire system. It's a little different then from what you think  object-orienting programming is today. One of the consequences is that there are no actual applications  because you can mix and match objects as you choose. Here we see something that  is vaguely familiar. Thought I'd turned that off. Okay, so this is a typical screen  back then, and it ran on the Alto there, the portable Notetaker and the Dorado.  Here's a bitmap painting I did 45 years ago that we found and stuck in  here. See the user interface is with the object itself, and here I'm marking it  up. It has a character recognizer, just a recognizer like GRAIL did. There, it's recognizing  I want an arrow and making one. The overlapping windows, the icons, what would be  rich text today, and you can see the gesture recognizer is being used to tell  it how to justify. This system is organized in terms of projects, so each project  you can think of in today's terms as a separate desktop. They persist over time.  Now think about this compared to the user interface today where you use an application  that doesn't every feature that you want, and you start and stop applications and try  and cut and paste between them. Here what you have is just working spaces, an  unlimited desk for every project that you have, you can have as many, they persist  over time, because this is a workflow idea. We couldn't get Apple to adopt this  idea. These are kind of thumbnails of each one of them, we can go into  one of them. Here's a little thing done by a 13-year-old girl writing an article  for Creative Computing back in 1975. You can see, it's sort of like desktop publishing,  but in fact, any object can be used in here, and so for example, if  we look here, she's telling about how she uses the computer and how she's typing  in there. She's typing in code and it's being executed to grow the box and  turn the box and so forth. Get the idea? It'd be nice if Wikipedia had  even thought about this, because imagine, you go to the article on Logo, guess what?  You can't execute Logo code in there. Why? It's on a computer. What didn't they  get about computing? Well, pretty much everything. If you look at it closely, you'll see  the web design and the web browser are two of the worst things ever done  in computing, because they fail to take account of the fact that you're actually on  a computer. Another example here is an animation system. You notice that ball is not  squashing there, and it would look better if the ball squashed when it hit. If  this were a normal system and it didn't have that feature, we'd be done, but  we can relate objects to each other. Here we're single-stepping to get to that frame  that we'd like to change. We're looking at the interface of this bouncing guy and  we're seeing, "Oh yeah, there's a thing called 'current frame', that's what this thing is."  Here's our painting window, and let's look at its interface. Here's something that allows me  to set the picture in there, and I want to connect the two windows together,  so I use the gesture recognizer to draw a line between them. It gives me  a little place to explain how I'd like to relate them, and I say, "Well,  the painter's picture wants to be the bouncing animation's current frame." Everybody get what's going  on here? I say, "Go ahead and do that," and now it's latched onto that  thing that's there. Now I can start the animation going again, but while it's going,  I can paint, look carefully and you'll see that the thing is being painted while  it's running. Wouldn't you like to be able to do that today? Just think about,  why not? This is like Sketchpad, except a few years later. Yeah. This is completely  natural, it's what you get very very easily if you just have unlimited objects. In  this particular thing gives you automatically something much more powerful than PowerPoint, because all you  have to do is sequence these things called projects or the desktops. That's what I'm  doing here, just moving from one to another. That's an example of what happened at  PARC, and if we go back to this screen of the various inventions there, we  can look at, now I'm answering Sam's question, how much of the Alto idea actually  made it out of Xerox PARC? Well, about half. We'll see what the other half  is in a second. How about the GUI? Well, about 70%, because you notice the  GUI didn't come out as something that has this unlimited desktop idea. Even today, 30  some odd years after this, nobody has put it in there. It's ridiculous, but it  has to do with people wanting to have applications and sell applications, even though most  applications won't do all the things that you need. How about desktop publishing? About 70%  for the same reason. The way we did programming, only about 10% has come out,  and I won't go into all the differences, but I think you've seen some of  them. Laser printer, about 90%. Post script, 100%, and that's partly because the guys who  did this at PARC formed Adobe, Geschke and Warnock. They sold as in their company  what it was, how they thought you should be able to do printing. 100% of  the ethernet, there was no competitor. About 50% of peer-peer and client server, we'll see  why in a second. 100% of the internet, again there was no competitor for it.  One way of looking at this is, what came out most successfully were the things  for which people already out there didn't think they already knew how to do it.  Everybody knew how to program, and so the biggest resistance was in how we did  programming. That just didn't make it. Here's three things that I didn't mention before because  none of them made it, but one of them was, hey, the architecture of the  Alto was revolutionary, and it allowed you to run very high level languages very efficiently  and to make changes on the fly. We tried with Intel and Motorola to get  them to adopt these architectures for the chip, and zero. Intel especially at the time  didn't know anything about computing, didn't know anything about programming, and didn't want to learn.  They had to be dragged kicking and screaming even to do CPUs. Andy Grove, for  instance, was against the first CPU on a chip that Intel did. The idea of  the Dynabook didn't make it out. If you think about it, when did the iPad  decide to put a stylus and a keyboard on the iPad? The iPad Pro. Why  couldn't they do it? What was their problem? 10% of that idea came out. Here's  an interesting idea to think about. Here we've got the internet of machines connected together,  and if your programming language happens to be a software internet, like Smalltalk was, then  you can map the objects into the network, and you can migrate the objects around.  Each object is self-contained, they do messaging, the messaging is either done internally or it  goes out on the internet, and so you have a solution for all the different  scalings of computing that you have, whether it's a small device. Yes?
Students: Why did you say only 10% of the Dynabook? What's so important about the stylus  and the keyboard?
Speaker 1: Well, here's the thing. Two-year-olds use this, and 92-year-olds use this. Everybody else uses tools  for dealing with media. When Steve decided not to do styluses, he completely went away,  all he was doing was selling sugar water to babies. He was not selling something,  for instance, that any artist can draw on. He sent me the first iPad for  my comments on the thing, and the first thing I did was go out and  get a capacitive stylus and draw lines with a ruler on, I guess it was  Autodesk, one of the Autodesk software that was pretty good. I determined that the touch-sensitivity  on the iPad was fabulous, despite the fact that it's done in a very, very  complex way. It has to find centroids from wide things on it, but it was  done extremely well and I got very linear results on it. It was there to  do, but there was no place to put on the stylus on the iPad, and  long long ago, remember I showed you a tablet system from the mid-60s, 50 years  ago. We had a perfect chance to decide by experiment whether a purely stylus-driven system  was actually enough to do the work that you wanted to do, and the answer  is no. Similarly with Englebart, you could do every piece of text entry without using  the keyboard, but they had a keyboard there because you just can't do it fast  enough for being able to put in large amounts of text. You need to have  a keyboard.
Students: tools for experts, by experts, like Englebart.
Speaker 1: Well, so here's the thing that Englebart said. They said, "Why do you have to  learn your system?" Back then, he said, "People are going to use their computers for  six to eight hours a day," and they laughed at him. What you guys are  doing, "Do, do, do, do," is using your computers for six to eight hours a  day and using interfaces that are made for a couple of seconds a day. If  that isn't the most ridiculous thing you've ever ... It's about as ridiculous as this  building. If you think about it as a user interface. You come in the door  and there's a stairway and there's no map. "Where am I, where can I go,  and Jesus, this looks like a dungeon." Remember, computer-human interface is part of what you're  supposed to learn about, and you can't do it in a dump like this. You  have to have some sense of design around, and I'm not sure you can do  software without having some sense of design around. I won't make any really rude remarks.  Just to use up time I don't have, I should point out that, some of  this migrating object idea was done at PARC, a really great followup was done by  a visitor to PARC, Jerry Popek, who then was at UCLA, went back to UCLA  and did a fabulous system using Unix as the base called Locus, L-O-C-U-S, and if  you're interested in a future that will at some point actually happen, you can get  that book from MIT Press, and particularly the first couple of chapters of that book  outline what the issues are for dealing with real scaling on the internet. I won't  go further than that. Zero. Principle 21, "Reality is a low-pass filter." You have to  have enormous ideas so that people not understanding them will retain something. You don't want  to have the low-pass filter give you back a dial tone. That happens, because most  ideas are mediocre down to bad, even by people who have good ideas. Those are  the ones that you don't want to work on, because if you're successful on them,  they're still going to get peeled down. Here's a book. I put this slide up  here for Sam, because Sam reads books. You people probably don't, but this is not  a book about Xerox PARC, Sam. This is a book by an executive at Xerox  written in the '60s, before PARC, about trying to get the Xerox machine adopted. This  was after Xerox had been the fastest-growing ... One of the companies that turned down  the complete rights for a licensing fee to the Xerox machine was IBM. That story  is in this book. IBM's consultant said, "This isn't going to work because there's no  market for plain paper copying, because people are not copying." Well, of course, it wasn't  a good copier back then. I could write a book, "Our Years With Xerox: The  Trillions Nobody Wanted". I didn't have time to make a picture that looks like John  Dessauer. It doesn't matter, and I'm going to try and explain to you in the  time I have left, why the goodness of an idea is almost irrelevant. Now for  the reality kit. Get out your reality kit, and we're going to deal with the  top. Let's break the seal and just open up the thing. This will work best  if you put it down on your thing like this. Look at the instructions. For  people online ... Did you get a reality kit? Okay. Everybody got one? What happened?  Where were you? Boy. Hey, you know what? You guys must have been late. Take  them, hand them out to ... Anybody else? Okay. You're killing me, guys. Okay, so,  cover your right eye, look at the plus with your left eye, and then slowly  the move thing in, keeping focused on the plus until something happens. Move slow, slow  as in the word "slow". Who's seeing something? What do you see?
Students: Disappears in our blind spot.
Speaker 1: Disappears in our blind ... Everybody seeing that? Don't say yes if you're not. This  is a good thing for everybody, particularly in computing, to do once a day. Okay,  so, now let me ask you, what do you see where the dot was? Nothing?
Students: Blur.
Speaker 1: What?
Students: Text.
Speaker 1: You see text. How could that be?
Students: The brain's algorithm fills in the spot with what it thinks it should see. It  fills in the spot with what the surroundings are.
Speaker 1: Why?
Students: That's what it expects.
Speaker 1: Okay, but here's what's happening here. You see something like this, right? What's happening is  inside your eye, I wonder if I've got a laser, yeah, over here is where  the blood vessels come through, so we have a very badly designed eye. If you're  arguing with a Creationist, this is a good argument against God here, because if there  was a God, he gave squids a great eye and he gave us a bad  one. Our eye happens to have the blood vessels in front of the light-detecting cells,  and so our brain has to filter out all of those also. Over here is  where most of your acuity is, in an area called the fovea. When the thing  is further away, you get something like this, and when you move in, at some  point the dot gets over where there are no light-sensitive cells at all and you  can't see it anymore. As my friend over here said, somehow the brain fills it  in. We'll look at that in a second. Principle number 22 is, we have a  blind spot in our eyes that our brain makes up stuff to fill in. It's  just making it up. Think about this because, what's the other case where your brain  makes up stuff that you think is real? A dream? Most people think they only  dream at night, but in fact human brains are set up so that we actually  dream ... Did you get one of these? In the old days we'd throw chalk  at you, but there is no chalk. A powerful idea about that is number 23,  is that we can't learn to see until we realize and admit that we're blind.  The biggest problem with most human beings is they don't understand that they are blind  because they think they can see. This leads to much of the trouble in the  world, and the powerful idea about that is the zeroth one again, is it makes  a huge difference if ideas are experienced in as many ways as possible. In other  words, perspective, point of view is worth 80 IQ points. Just because something seems to  be right, and this is why math is a danger about thinking. Okay, let's go  to the poker chips now. Pry them loose. Okay, and what you're going to do  is hold them up like this, so one is about twice as far away as  the other, like that. Okay, you'll see something like this, right? On your retina is  actually something like this. Think about it. If it's twice as far away, it's subtending  half the angle, and therefore it should show up as half size, but it doesn't  show up as half size. We can stick these guys on a ruler, since these  poker chips are now yours, you can take it back and really science the shit  out of it. Here's what we should see, that's what's on our retina. Descartes, by  the way, got an ox eye and peeled the back of it off to see  whether biological lenses actually acted like glass lenses, and they do. Here's what's going on.  The stuff that's on your retina gets mapped into about 12 different places in your  brain. Your brain is active. In computer terms, the cells in your brain are like  the hardware, and there are processes going on, and one set of processes are all  the ones that have to do with our belief system. Before we recognize something, it  goes through our belief system, and then it goes into the real time version of  our belief system, which is called the dream. We have beliefs in the dream, and  our beliefs are, "Dammit, these things are the same size." By the way you can  do this with oranges, with quarters, anything where you know they're the same size, do  the same thing. The result of information from the actual world combined with your beliefs,  you wind up with this. Anybody here is an artist who can draw? Okay. You  must know this illusion then, it's called size constancy. Can you actually draw? Yeah. You  can draw, right? If you can actually draw, the first thing you realize is you  can't see what's going on, and so you start measuring. Hold your arm rigid, you  measure it off, so I can measure, yeah, Sam's head is that high. Wow, it's  only half size compared to this guy who's closer to me. It doesn't look like  it to me, it looks like it's almost the same size because heads are the  same. Got it? Principle 24, the mind's eye is different than our sensory eye. We  do things according to the mind's eye, and most people who have ever lived on  this planet don't know that there are two different eyes, because they take the world  as it seems. They build up a common sense from the world as it seems.  This is why human beings generally cannot think. You can't think if you're doing this  stuff. Another term for beliefs is a "private universe". We each have one of our  very own. If you've ever argued with somebody you thought was reasonable up to that  point, what's happening is, your beliefs are conflicting with their beliefs. Our waking dreams are  private. I love this phrase. This is a new phrase, "alternate truths", Kellyanne Conway. That's  what's going on. You can see why being a scientist is tough. The scientist has  to get around all of this crap that our brain is throwing up. Okay, so,  a quick easy model is how randomness is, is a little bit of rainwater on  dirt, dislodges a few crumbs of dirt and a little gully happens, and the gully  is more efficient at routing water, so things start happening. Just where things started happening  originally, you get something like this. Completely random, it could have gone anyway. You make  a whole world out of it. Here's a world that's completely pink, if you've ever  been in the Grand Canyon, it is just almost overwhelming. If you look up, you  have to remember to look up, there's a little bit of blue sky up above.  The problem with human beings is we don't look up. We look out. Here's an  example. That's pretty washed out, but that's a pink plane, and our thoughts are like  ants crawling over it. We can think about things, we can make progress, we can  run into an obstacle, we can get around the obstacle, and so forth, but everything  we're doing here is pink except we don't know it's pink because we've never been  in anything else but pink. This is like a fish not knowing it's in water.  It's always been in water. Every once in a while, you might have a little  outlaw thought, a little blue thought, but you've been to school, you're going to Stanford,  you go to church, temple, synagogue, mosque, whatever it is, because our beliefs project out.  When we see something that isn't normal, normal is actually the same as crazy. Smash.  maybe you're out for a run, you're just waking up in the morning, you're taking  a shower, and all of a sudden, you get a, "Holy shit, holy shit, there's  a blue world, a blue world that's orthogonal to the one I'm in." Once you're  in that blue world, you realize, "Oh, there's probably a lot of them." Can you  see each one of these as a context? Can you see that what happened from  the Renaissance by Newton, to our modern age, was going from a pink plane to  a blue plain? This is what ARPA did with computing. It went from mainframes, a  completely different way of thinking about things, to the world we have today, despite the  fact that nobody had thought of it at all. It was considered literally crazy by  our colleagues in computing when we were doing it. Okay. Just leave the compass on  there. It's for you to remember that some people get to this really early. Einstein  was five, he was recovering from the measles, I think. His father brought him a  little compass for him to play with, and Einstein remembered later in life. He said,  "This made the most impression of me of anything in my childhood," because the way  he looked at it, "Oh, there must be something deeply hidden behind things." He didn't  take it as it came because he was worrying about, how does the needle know  where to go? There's nothing visible about it, and yet it is doing this, and  that changed Einstein's complete way of thinking about things. When a baby is born, when  we are born, we're not born into nothing. We're born into a culture. Most cultures  over the last hundred-plus, thousands of years were traditional cultures, hunting and gathering cultures. Traditional  cultures don't know that they are inside a particular outlook. Traditional cultures think they're in  reality. They react incredibly strongly to other people's versions of reality, to the point of  war. This is what are genes give rise to, and many people today including in  our country are born into this pretty natural way of looking at things. We had  to invent the idea of outlook. Well, here's another one. If you happen to be  born here, you can have the same baby and bring it up here, the baby  will grow into being French, French in its outlook, French in language, and so forth.  Here's a big idea. What happens when books got invented? A guy by the name  of Marshall McLuhan asked the question, "What are books? What is writing as an environment?"  If you thought of writing as being brought up in France, what would that actually  mean to the human race? It turns out, it's profound. Take a look at it  if you're interested. He also asked, "What is media as an environment?" For example, what  is this as an environment 24-7? Think about it. Not that the kids are being  told to shoot people, but the problem is, they're seeing shooting people as normal, because  what environments do is to take things and normalize them. They make them into part  of reality and make things thinkable. They don't say what to do, and of course  media that we have today is doing exactly the same thing, and most people don't  realize. Okay, so, unhook the last flap here. There's a little desktop here, tabletop. Look  at the picture there first and before you start experimenting, let me make an assertion  that the tops of the tables are exactly the same shapes. I've been doing this  hundreds of times and I can't see it, but if I take my plastic thing  and move it over there ...
Students: That's crazy.
Speaker 1: Yeah. No, it isn't crazy, we are crazy. If you remember nothing else from this  course, remember that the natural state of humanity is to be crazy, because crazy is  not having good models in our mind for what's going on out there. We just  draw the line at certain kinds of crazy, but we're actually crazy. This is a  really good one, isn't it? Happens to have been first done here at Stanford, this  guy is Roger Shepard, and his book is full of these. Good. Last couple of,  yeah, I think I'll get through. Anthropologists over the last 120 years or so studied  several thousand traditional cultures and wrote down properties of these cultures that were never absent.  If a single culture out of several thousand did not have a trait, then that  trait was removed. All of these traits are thought of as human universals, virtually all  of them are genetic. Here's a book. You know, books are actually useful. It's another  good one to read.
Students: This is a great book.
Speaker 1: Yeah. I became very friendly with Sam when I noticed I could not mention a  book to him that he would not have read the next time I saw him.  That's how you know he's a good guy. Okay, so the basic idea is, genetics  drives culture. Genetics has the precursors, the desires, and culture fills in the parameters. You  can think of these, they're all category names. Once that list was made, people got  interested in things that were not in every culture. This is a partial list of  those. Agriculture had to be invented. It was a pretty easy invention, but it was  only invented about 12,000 years ago, out of several hundred thousand years of us being  on the planet. Initially, it was a hard thing for hunting and gathering people to  think about. Like every animal, we have zillions of genes to help us cope with  things. We can deal with hardship, like every animal, incredibly, but the idea of progress  had to be invented. It's really an invention of the 18th century. The reason is  that, for almost all of human existence, people died in the same world that they  were born into. Almost nothing happened, and so what you had to do to get  from birth to death was to cope. It's only been recently that the idea of,  "No, we can shape the world to be better." That's a new idea. These are  all powerful ideas. Oral language versus writing and reading, the differences are profound. Stories, superstition,  religion and magic, versus the representation systems of science. News. Remember, news never introduces a  new category. What you hear about is, "Oh, it's this forest fire, it's that war,  it's this murder, it's this kind deed." This is why news can happen so quickly.  That's what our mind craves. What we hate is categories, because it can take us  a couple of years to learn the category. You never hear any news about calculus.  It takes a couple of years to learn it and there aren't enough people. Fast  thinking versus slow thinking. Differences over similarities. This is one of the reasons why most  programming languages go bad and the web browser went bad, whereas a modern way of  thinking about things is similarities over differences, emphasizes similarities. It has many things to do  also with equal rights and democracy. Vendetta and revenge, those are the favorite movies, and  the favorite video games are revenge games, personal revenge games where the system has gone  and somebody has to break the law to put things right. We just love that  trope, but in fact, the whole legal system was set up in order to avoid  thousand-year feuds and vendettas. We can think of this side, we have things that human  beings want. A simple way of thinking about them is, every single one of them  on this side is a legal drug, and for people in this class who are  trying to make money by being entrepreneurs, just make a technological amplifier for any of  these things that we crave genetically. Look at the things that are there. Hunting and  gathering, social language, like the telephone. Stories, news, theater, all of those things. That's your  list. Just get this book. Right, Sam? Make something that will make people worse, and  they'll buy the hell out of it, because we don't have any natural ... All  of these things are in shortage in the world that human beings have been into  except for a couple hundred years ago. Over here we have things that human beings  need, and you can't really see, but these are terribly difficult to learn because they're  not particularly genetically prepared for. They had to be invented. Last shot here, 21st century,  going out of the 22nd century. Hey, we're not born into France or traditional society  anymore. We're born into a universe that is unbelievably large, a planet that most people  don't even realize we're on yet. Not just our social system of a few hundred  people that we know, but millions of social systems and billions of people. A technological  system that is starting to touch everybody in many many different ways. For instance, modern  medicine really dates from only World War II. That's a long time ago for you  folks, but it's within my lifetime. I was born before World War II, and before  World War II, you simply did not get antibiotics when you had an infection. It  was that soon. Doctoring was almost quackery, so much of scientific medicine has happened in  the last 50 or 60 years. Then we have the system of our mind. There's  not just social, but psychological, cognitive, and so forth. We can sum up this world  that we're born into in this century as the systems we live in and the  systems we are. Think about that, the difference between that and what most people think  that they want. These are the systems we have to learn about and deal with.  These systems are not separate. I've mentioned them separately, but they're all intertwined with each  other. They're all invisible. Okay. I'll just leave you with this last slide. We found  out about all of these systems, they were invisible until a few hundreds years ago,  and some of them invisible until a few years ago. The human tragedy is in  two parts. Part of it is just finding out, something in our civilization doesn't automatically  transmit it to people born into the civilization. The educational system has to be changed  in order to reflect this stuff. The composite picture here is that part of our  brain, the genetic part of our brain, even overlaid with this stuff, still has these  reactions and ways of thinking about things or not thinking about things that go back  100,000 years. I think with things like television to look at, things like video games  to look at, things like Facebook to look at, if you're going to go out  and make a company that is going to appeal to people, try to do it  without appealing to the parts of their nature that they're helpless in front of, because  one of the things that those of us who helped invent the technologies of today  are quite worried about now is that the technology is so much easier to invent  than it is to change the educational system. What we've got is, the informational equivalent  of cave people with nuclear weapons. Now they're informational weapons, and in many ways I  think these weapons are more dangerous because by re-normalizing human attitudes and human beliefs could  very easily bring down our civilization and put us back into the Stone Age. The  talk on Tuesday may be a little thicker today, but the whole impetus behind the  ARPA research and inventions of these things, and particularly people like Englebart, was to try  to invent new tools and new media for humanity to get itself out of its  problems. Englebart, for example, said, "Almost everything important that has consequence in the adult world  is done by adults working together." This is why his system was collaborative. Here's an  interesting thing. Here's a Mac. Some people have Linux, some people have Windows on it.  Here's the interesting thing. Not a single one of the main operating systems today has  built into it the thing that Englebart showed in 1968, which is the intrinsic thing  to ability to share any content that you're looking at with anybody else, to the  point of allowing them to interact with it and to talk back and forth. Skype,  it doesn't do it. This is a thing that is at an operating system level.  It's not a trivial thing to do. It is possible to do but not a  single operating system used today does it, and so the ability to actually work collaboratively  on content has been held back by notions of operating systems that go back pre-1965.  All three operating systems we have today that are the main ones are old, old  ideas. They don't even get to where PARC was on the notion of how processes  can coordinate with each other. There are many, many other of these things. Because these  operating systems are rather similar to each other and because they're pervasive, unless you use  your reality kit, you're going to think that they're normal and therefore that's the way  things should be. Many people in computing have a misplaced notion of Darwinian process, like  most people. Most people think Darwinian processes optimize. That is absolutely not the truth. One  of my degrees is in molecular biology, and I can tell you any biologist would  say, they absolutely not optimize. The whole point of Darwinian processes is to fit into  some niche and some environment. If that environment isn't the right kind of environment, the  process of evolution is not going to give you something that's very interesting. That is  the way it works. As computing gets less and less interesting, its way of accepting  and rejecting things gets more and more mundane. This is why some of these early  systems, like Sam looked at Sketchpad and said, "Why aren't they doing it today?" Well,  because nobody even thinks about that that's important. Nobody even thinks of doing WYSIWYG on  web media. I just typed in some answers to CORA, and I was in a  regime that was pre-'70s. I was typing into a little window, I couldn't see what  it was going to look like until I clicked the button. Come on, this is  bullshit, but nobody is protesting except old fogies like me, because I know it can  be better. You need to find out that it can be better. That is your  job. Your job is not to agree with me. Your job is to wake up,  find ways of criticizing the stuff that seems normal. That is the only way out  of the soup. You have to go against your genetic impulses to try and learn  the environment around you. It's the most natural thing we have, but it's not going  to help, because the environment is weak, and if you learn the environment, you're going  to be weak.
Speaker 3: All right. Thank you very much. 
